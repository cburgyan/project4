{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define paths\n",
    "data_dir = 'data'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "# The test_ratio is implicitly defined as what's left after allocating for training and validation\n",
    "\n",
    "# Get the classes\n",
    "classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d)) and d not in ['train', 'val', 'test']]\n",
    "\n",
    "# Split the data\n",
    "for cls in classes:\n",
    "    # Create directories for each class in train, val, and test directories\n",
    "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
    "\n",
    "    # List images in each class directory\n",
    "    images = os.listdir(os.path.join(data_dir, cls))\n",
    "    np.random.shuffle(images)  # Shuffle the images\n",
    "\n",
    "    # Split images into train, val, and test\n",
    "    train_count = int(train_ratio * len(images))\n",
    "    val_count = int(val_ratio * len(images))\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        if i < train_count:\n",
    "            dest = os.path.join(train_dir, cls)\n",
    "        elif i < train_count + val_count:\n",
    "            dest = os.path.join(val_dir, cls)\n",
    "        else:\n",
    "            dest = os.path.join(test_dir, cls)\n",
    "\n",
    "        # Move image\n",
    "        shutil.move(os.path.join(data_dir, cls, img), os.path.join(dest, img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17728 images belonging to 8 classes.\n",
      "Found 5062 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "\n",
    "        'data/val',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_for_frozen_training_phase = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "554/554 [==============================] - 1227s 2s/step - loss: 1.6524 - accuracy: 0.5341 - val_loss: 1.1818 - val_accuracy: 0.5858\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1244s 2s/step - loss: 1.2510 - accuracy: 0.5632 - val_loss: 1.1391 - val_accuracy: 0.6013\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1287s 2s/step - loss: 1.2275 - accuracy: 0.5667 - val_loss: 1.1171 - val_accuracy: 0.6054\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1316s 2s/step - loss: 1.2128 - accuracy: 0.5654 - val_loss: 1.0993 - val_accuracy: 0.6032\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1329s 2s/step - loss: 1.2019 - accuracy: 0.5649 - val_loss: 1.1111 - val_accuracy: 0.6046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1dafb6d3910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=epochs_for_frozen_training_phase,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f'./Results/skinModelAfter{epochs_for_frozen_training_phase}EpochsFrozenTraining_{timestamp}.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_after_thawing_training_phase = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "554/554 [==============================] - 1328s 2s/step - loss: 1.1291 - accuracy: 0.5948 - val_loss: 1.0735 - val_accuracy: 0.6214\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 1325s 2s/step - loss: 1.1006 - accuracy: 0.6130 - val_loss: 1.0756 - val_accuracy: 0.6179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1dafb6d2860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Unfreeze some layers in the base model\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Recompile the model (necessary after making changes to layer.trainable)\n",
    "# Reduce Learning rate of Adam to prevent more dramatic changes in the top (recently thawed) layers\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=epochs_after_thawing_training_phase,  # specify additional epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f'./Results/skinModelAfter{epochs_for_frozen_training_phase}EpochsOfThawedTraining{timestamp}.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2541 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Assuming the same preprocessing as training and validation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "# Now define the test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  # make sure batch_size is defined\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 135s 2s/step - loss: 1.0741 - accuracy: 0.6199\n",
      "Test accuracy: 0.6198576092720032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "dict_results = {}\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.n // test_generator.batch_size)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "dict_results['test_accuracy'] = test_accuracy\n",
    "dict_results['Optimization_Title'] = f\"try training with {epochs_for_frozen_training_phase} frozen epochs under a learning_rate of 0.001 (adam optimizer) and {epochs_after_thawing_training_phase} epochs with a learning_rate of {learning_rate}\"\n",
    "dict_results['num_of_training_images_removed'] = 0\n",
    "dict_results['num_of_training_images'] = train_generator.n\n",
    "dict_results['num_of_validation_images_removed'] = 0\n",
    "dict_results['num_of_validation_images'] = validation_generator.n\n",
    "dict_results['num_of_inputs'] = model.input_shape\n",
    "dict_results['test_loss'] = test_loss\n",
    "dict_results['learning_rate'] = model.optimizer.learning_rate.numpy()\n",
    "\n",
    "# Redirect console printout to io.StringIO to collect it as a string\n",
    "summary_str = io.StringIO()\n",
    "with redirect_stdout(summary_str):\n",
    "    model.summary()\n",
    "\n",
    "dict_results['model_summary'] = summary_str.getvalue()\n",
    "dict_results['Optimizer_details'] = model.optimizer.get_config()\n",
    "dict_results['batch_size'] = 32\n",
    "dict_results['target_size'] = (224, 224)\n",
    "dict_results['class_mode'] = 'categorical'\n",
    "\n",
    "file_path = \"./Results/optimization_results.txt\"\n",
    "\n",
    " # Open the file in append mode\n",
    "with open(file_path, \"a\") as file:\n",
    "    # Append a line to the file\n",
    "    # line_to_append = \"This is a new line to append to the file.\"\n",
    "    file.write(str(dict_results).replace(',', ',\\n') + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_accuracy': 0.6182753443717957, 'Optimization_Title': 'try training with 5 frozen epochs under a learning_rate of 0.001 (adam optimizer) and 2 epochs with a learning_rate of 0.0001', 'num_of_training_images_removed': 0, 'num_of_training_images': 17728, 'num_of_validation_images_removed': 0, 'num_of_validation_images': 5062, 'num_of_inputs': (None, 224, 224, 3), 'test_loss': 1.0774253606796265, 'learning_rate': 1e-04, 'model_summary': None, 'Optimizer_details': {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'batch_size': 32, 'target_size': (224, 224), 'class_mode': 'categorical'}\n"
     ]
    }
   ],
   "source": [
    "print(str(dict_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_accuracy': 0.6198576092720032,\n",
      " 'Optimization_Title': 'try training with 5 frozen epochs under a learning_rate of 0.001 (adam optimizer) and 2 epochs with a learning_rate of 0.0001',\n",
      " 'num_of_training_images_removed': 0,\n",
      " 'num_of_training_images': 17728,\n",
      " 'num_of_validation_images_removed': 0,\n",
      " 'num_of_validation_images': 5062,\n",
      " 'num_of_inputs': (None,\n",
      " 224,\n",
      " 224,\n",
      " 3),\n",
      " 'test_loss': 1.0740506649017334,\n",
      " 'learning_rate': 1e-04,\n",
      " 'model_summary': 'Model: \"model_1\"\\n_________________________________________________________________\\n Layer (type)                Output Shape              Param #   \\n=================================================================\\n input_2 (InputLayer)        [(None,\n",
      " 224,\n",
      " 224,\n",
      " 3)]     0         \\n                                                                 \\n block1_conv1 (Conv2D)       (None,\n",
      " 224,\n",
      " 224,\n",
      " 64)      1792      \\n                                                                 \\n block1_conv2 (Conv2D)       (None,\n",
      " 224,\n",
      " 224,\n",
      " 64)      36928     \\n                                                                 \\n block1_pool (MaxPooling2D)  (None,\n",
      " 112,\n",
      " 112,\n",
      " 64)      0         \\n                                                                 \\n block2_conv1 (Conv2D)       (None,\n",
      " 112,\n",
      " 112,\n",
      " 128)     73856     \\n                                                                 \\n block2_conv2 (Conv2D)       (None,\n",
      " 112,\n",
      " 112,\n",
      " 128)     147584    \\n                                                                 \\n block2_pool (MaxPooling2D)  (None,\n",
      " 56,\n",
      " 56,\n",
      " 128)       0         \\n                                                                 \\n block3_conv1 (Conv2D)       (None,\n",
      " 56,\n",
      " 56,\n",
      " 256)       295168    \\n                                                                 \\n block3_conv2 (Conv2D)       (None,\n",
      " 56,\n",
      " 56,\n",
      " 256)       590080    \\n                                                                 \\n block3_conv3 (Conv2D)       (None,\n",
      " 56,\n",
      " 56,\n",
      " 256)       590080    \\n                                                                 \\n block3_conv4 (Conv2D)       (None,\n",
      " 56,\n",
      " 56,\n",
      " 256)       590080    \\n                                                                 \\n block3_pool (MaxPooling2D)  (None,\n",
      " 28,\n",
      " 28,\n",
      " 256)       0         \\n                                                                 \\n block4_conv1 (Conv2D)       (None,\n",
      " 28,\n",
      " 28,\n",
      " 512)       1180160   \\n                                                                 \\n block4_conv2 (Conv2D)       (None,\n",
      " 28,\n",
      " 28,\n",
      " 512)       2359808   \\n                                                                 \\n block4_conv3 (Conv2D)       (None,\n",
      " 28,\n",
      " 28,\n",
      " 512)       2359808   \\n                                                                 \\n block4_conv4 (Conv2D)       (None,\n",
      " 28,\n",
      " 28,\n",
      " 512)       2359808   \\n                                                                 \\n block4_pool (MaxPooling2D)  (None,\n",
      " 14,\n",
      " 14,\n",
      " 512)       0         \\n                                                                 \\n block5_conv1 (Conv2D)       (None,\n",
      " 14,\n",
      " 14,\n",
      " 512)       2359808   \\n                                                                 \\n block5_conv2 (Conv2D)       (None,\n",
      " 14,\n",
      " 14,\n",
      " 512)       2359808   \\n                                                                 \\n block5_conv3 (Conv2D)       (None,\n",
      " 14,\n",
      " 14,\n",
      " 512)       2359808   \\n                                                                 \\n block5_conv4 (Conv2D)       (None,\n",
      " 14,\n",
      " 14,\n",
      " 512)       2359808   \\n                                                                 \\n block5_pool (MaxPooling2D)  (None,\n",
      " 7,\n",
      " 7,\n",
      " 512)         0         \\n                                                                 \\n flatten_1 (Flatten)         (None,\n",
      " 25088)             0         \\n                                                                 \\n dense_2 (Dense)             (None,\n",
      " 1024)              25691136  \\n                                                                 \\n dropout_1 (Dropout)         (None,\n",
      " 1024)              0         \\n                                                                 \\n dense_3 (Dense)             (None,\n",
      " 8)                 8200      \\n                                                                 \\n=================================================================\\nTotal params: 45723720 (174.42 MB)\\nTrainable params: 25699336 (98.04 MB)\\nNon-trainable params: 20024384 (76.39 MB)\\n_________________________________________________________________\\n',\n",
      " 'Optimizer_details': {'name': 'Adam',\n",
      " 'weight_decay': None,\n",
      " 'clipnorm': None,\n",
      " 'global_clipnorm': None,\n",
      " 'clipvalue': None,\n",
      " 'use_ema': False,\n",
      " 'ema_momentum': 0.99,\n",
      " 'ema_overwrite_frequency': None,\n",
      " 'jit_compile': False,\n",
      " 'is_legacy_optimizer': False,\n",
      " 'learning_rate': 1e-04,\n",
      " 'beta_1': 0.9,\n",
      " 'beta_2': 0.999,\n",
      " 'epsilon': 1e-07,\n",
      " 'amsgrad': False},\n",
      " 'batch_size': 32,\n",
      " 'target_size': (224,\n",
      " 224),\n",
      " 'class_mode': 'categorical'}\n"
     ]
    }
   ],
   "source": [
    "print(str(dict_results).replace(',', ',\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45723720 (174.42 MB)\n",
      "Trainable params: 25699336 (98.04 MB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict_results['model_summary'] = \n",
    "type(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "summary_str = io.StringIO()\n",
    "with redirect_stdout(summary_str):\n",
    "    model.summary()\n",
    "\n",
    "# Now summary_str.getvalue() contains the summary as a string\n",
    "print(type(summary_str.getvalue()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "# !pip install keras_tuner\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import keras_tuner as kt\n",
    "import datetime\n",
    "import shutil\n",
    "import keras\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    # nn_model = tf.keras.models.Sequential()\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "\n",
    "    # Freeze the layers of the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "    num_layers = hp.Int('num_layers', 1, 2)\n",
    "\n",
    "    # activation = hp.Choice('activation_layer_input', ['relu', 'leaky_relu'])\n",
    "\n",
    "\n",
    "\n",
    "    # Add custom layers\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Add new layers based on hyperparameters\n",
    "    for i in range(1, num_layers):\n",
    "        # Get the number of neurons and activation for this layer\n",
    "        num_neurons = hp.Int(f'activation_of_layer_{i}_after_VGG19_base_model', min_value=512, max_value=2048, step=256)\n",
    "        activation = hp.Choice(f'activation_of_layer_{i}', ['relu', 'leaky_relu'])\n",
    "\n",
    "        # Add the Dense layer\n",
    "        if activation == 'leaky_relu':\n",
    "            x = Dense(num_neurons)(x)  # Add Dense layer without activation\n",
    "            x = tf.keras.layers.LeakyReLU(alpha=0.01)(x)  # Add separate LeakyReLU layer\n",
    "        else:\n",
    "            x = Dense(num_neurons, activation=activation)(x)\n",
    "\n",
    "    num_neurons_for_layer = hp.Int(f'num_neurons_for_layer_{num_layers}_afterVGG19_base_model',\n",
    "            min_value=512,\n",
    "            max_value=2048,\n",
    "            step=256)\n",
    "    activation = hp.Choice('activation_layer_input', ['relu',  'leaky_relu'])\n",
    "\n",
    "    # Add custom layers\n",
    "    # x = base_model.output\n",
    "    # x = Flatten()(x)\n",
    "    x = Dense(num_neurons_for_layer, activation=activation)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "\n",
    "    # output layer\n",
    "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete old dirctory used by keras_tuner.Hyperband before a new keras_tuner.Hyperbad is made\n",
    "def delete_directory_and_its_content(directory_name):\n",
    "\n",
    "    # Use shutil.rmtree() to recursively delete directories and subdirectories\n",
    "    try:\n",
    "        shutil.rmtree(directory_name)\n",
    "        print(f\"Directory '{directory_name}' has been deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './untitled_project/' has been deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "\n",
    "delete_directory_and_its_content('./untitled_project/')\n",
    "tuner = kt.Hyperband(\n",
    "            create_model,\n",
    "            objective=\"val_accuracy\",\n",
    "            max_epochs=max_epochs,\n",
    "            hyperband_iterations=8,\n",
    "            seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 Complete [00h 40m 15s]\n",
      "val_accuracy: 0.5320411324501038\n",
      "\n",
      "Best val_accuracy So Far: 0.6392405033111572\n",
      "Total elapsed time: 19h 24m 30s\n",
      "\n",
      "Search: Running Trial #14\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |2                 |num_layers\n",
      "768               |1792              |num_neurons_for_layer_1_afterVGG19_base_model\n",
      "leaky_relu        |relu              |activation_layer_input\n",
      "0.00079743        |0.00028406        |learning_rate\n",
      "1024              |512               |activation_of_layer_1_after_VGG19_base_model\n",
      "leaky_relu        |relu              |activation_of_layer_1\n",
      "1792              |512               |num_neurons_for_layer_2_afterVGG19_base_model\n",
      "2                 |5                 |tuner/epochs\n",
      "0                 |2                 |tuner/initial_epoch\n",
      "1                 |1                 |tuner/bracket\n",
      "0                 |1                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "424/554 [=====================>........] - ETA: 26:13 - loss: 2.5630 - accuracy: 0.4931"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\T852\\DataScienceCourse\\project4\\ExploratoryFiles\\skinLesionClassificationTarget_Images\\skinLesionTarget_Images.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/T852/DataScienceCourse/project4/ExploratoryFiles/skinLesionClassificationTarget_Images/skinLesionTarget_Images.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/T852/DataScienceCourse/project4/ExploratoryFiles/skinLesionClassificationTarget_Images/skinLesionTarget_Images.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/T852/DataScienceCourse/project4/ExploratoryFiles/skinLesionClassificationTarget_Images/skinLesionTarget_Images.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mtrain_generator\u001b[39m.\u001b[39;49mn \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m train_generator\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/T852/DataScienceCourse/project4/ExploratoryFiles/skinLesionClassificationTarget_Images/skinLesionTarget_Images.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mmax_epochs \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/T852/DataScienceCourse/project4/ExploratoryFiles/skinLesionClassificationTarget_Images/skinLesionTarget_Images.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/T852/DataScienceCourse/project4/ExploratoryFiles/skinLesionClassificationTarget_Images/skinLesionTarget_Images.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_generator\u001b[39m.\u001b[39;49mn \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m validation_generator\u001b[39m.\u001b[39;49mbatch_size\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/T852/DataScienceCourse/project4/ExploratoryFiles/skinLesionClassificationTarget_Images/skinLesionTarget_Images.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    272\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    274\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    275\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 238\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    240\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    241\u001b[0m     ):\n\u001b[0;32m    242\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    243\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    246\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    254\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    426\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[39m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\T852\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=max_epochs + 1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_results = {}\n",
    "first_model = tuner.get_best_models(num_models=1)[0]\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "filename = f'./Results/skinModelAfter{epochs_for_frozen_training_phase}EpochsOfThawedTraining{timestamp}.h5'\n",
    "first_model.save(filename)\n",
    "test_loss, test_accuracy = first_model.evaluate(test_generator, steps=test_generator.n // test_generator.batch_size)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "dict_results['test_accuracy'] = test_accuracy\n",
    "dict_results['Optimization_Title'] = f\"try training with Hyperband with {epochs_for_frozen_training_phase} frozen epochs under a learning_rate of 0.001 (adam optimizer) with up to 8 hyperband iterations and between 1 and 2 layers (not including output layer) BEYOND the base_model given by VGG19\"\n",
    "dict_results['num_of_training_images_removed'] = 0\n",
    "dict_results['num_of_training_images'] = train_generator.n\n",
    "dict_results['num_of_validation_images_removed'] = 0\n",
    "dict_results['num_of_validation_images'] = validation_generator.n\n",
    "dict_results['num_of_inputs'] = first_model.input_shape\n",
    "dict_results['test_loss'] = test_loss\n",
    "dict_results['learning_rate'] = first_model.optimizer.learning_rate.numpy()\n",
    "\n",
    "# Redirect console printout to io.StringIO to collect it as a string\n",
    "summary_str = io.StringIO()\n",
    "with redirect_stdout(summary_str):\n",
    "    first_model.summary()\n",
    "\n",
    "dict_results['model_summary'] = summary_str.getvalue()\n",
    "dict_results['Optimizer_details'] = first_model.optimizer.get_config()\n",
    "dict_results['batch_size'] = 32\n",
    "dict_results['target_size'] = (224, 224)\n",
    "dict_results['class_mode'] = 'categorical'\n",
    "\n",
    "file_path = \"./Results/optimization_results.txt\"\n",
    "\n",
    " # Open the file in append mode\n",
    "with open(file_path, \"a\") as file:\n",
    "    # Append a line to the file\n",
    "    # line_to_append = \"This is a new line to append to the file.\"\n",
    "    file.write(str(dict_results).replace(', \"', ',\\n\"') + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
